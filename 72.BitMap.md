# Bit Map

## Bit Map

Bit Map 可以想成一種特殊的 Hash table，目的是降低儲存所需的空間  

例如，有一千萬個整數，範圍在 1 到 1 億間，如何搜尋某個數是否在這一千萬個整數中?  

把一千萬個整數的數字所對應陣列的索引設為 `true`，例如 5 在其中就把 `array[5] = true`，要找 k 就檢查 `array[k]` 是否為 `true`  

但 `boolean` 資料型態大部分是 1 byte，而表示 `true` 或 `false` 只需要一個 bit 即可，方法是對資料型態如 `int`、`long`、`char` 透過位元運算，用其中的位元表示數字

```java
public class BitMap {
    private char[] bytes;	// char 16 bit
    private int nbits;	// 範圍
    
    public BitMap(int nbits) {
        this.nbits = nbits;
        this.bytes = new char[nbits / 16];
    }
    
    public void set(int k) {
        if (k > nbits) return;
        int byteIndex = k / 16;	// 第幾個 byte 中的第幾個 bit
        int bitIndex = k % 16;
        bytes[byteIndex] |= (1 << bitIndex);	// 設為 1
    }
    
    public void get(int k) {
        if (k > nbits) return;
        int byteIndex = k / 16;
        int bitIndex = k % 16;
        return (bytes[byteIndex] & (1 << bitIndex)) != 0;
    }
}
```

如果範圍不大的情況下，非常省空間；前面的例子使用 Hash table 儲存 1 千萬個 32 bit 的整型需要約 40 MB

```
32 bit = 4 byte
4 * 10000000 = 40000000 byte
40 MB
```

透過 Bit Map 儲存，因為範圍在 1 到 1 億，只需要 1 億個 bit

```
100000000 bit = 25000000 byte
12.5 MB
```

但如果範圍太大，例如範圍是 1 到 10 億之間，這樣就需要 120 MB，反而比 Hash Table 還多



## Bloom Filter

Bloom Filter 是 Bit Map 的改良版，解決範圍過大時反而造成儲存空間需要更多的問題  

假設範圍是 1 到 10 億之間，但仍然使用 1 億個 bit 表示；透過 hash function 讓 1 到 10 億數字落在 1 億之內，例如 $f(x) = x\mod n$ 

### 衝突處理

為了避免衝突，採用多個 hash function，例如設定一個數字，可以使用 $K$ 個 hash function 求出 $X_1$、$X_2$、…、$X_k$，將 $BitMap[X_1]$、…、$BitMap[X_k]$ 皆設為 `1`

判斷一個數字是否存在，可以使用 $K$ 個 hash function 求出 $X_1$、$X_2$、…、$X_k$，將 $BitMap[X_1]$、…、$BitMap[X_k]$ 是否皆為 `1`，如果其中一個為非則不存在  

使用了 $K$ 個二進制位來表示一個數字的存在

### 誤判

根據以上的思路會發現，使用 Bloom Filter 判斷一個數字不存在時，一定不存在；判斷為存在時，有可能不存在，只是因為所有 hash function 出來的二進制位都剛好是 `1` 而已

> Bloom Filter. False is always false. True is maybe true.

誤判率與資料密集程度有關，有就是插入的量與範圍的關係，當 Bit Map 中 `true` 越多後，誤判機率越高，因此也需要 resize 機制

因為誤判的關係，Bloom Filter 只能應用在不需要百分百準確地場景，例如網頁爬蟲、網站每日 UV 數

#### 網頁爬蟲

假設有 10 億個網址要爬，爬取前先確認該網址是否已爬過，所以需要一個資料結構能夠儲存、搜尋爬過的網址  

估算 Hash table 需要多少儲存空間，每個 URL 長度為 64 byte，10 億個大約 60 GB；但 Hash table 為了避免衝突，會設定 load factor 避免資料太密集，加上使用 separate chaining 還要多儲存指標，實際需要的可能超過 100 GB  

改用 Bloom Filter，10 億個網址用 10 倍的 bit 儲存，大約需要 1.2 GB；而以爬蟲系統而言，在判斷該網址是否已爬過，Bloom Filter 判斷為存在(已爬過)，實際上沒爬過，有一點誤差也能接受  

且 Bloom Filter 使用多個 hash function 處理一個 URL 時，只需要從記憶體中讀取一次，進行多次運算出 hash 值，理論上屬於 CPU 密集型操作；但 Hash table 處理衝突時，需要走訪串列進行判斷，且每次判斷是做字串的匹配，過程涉及很多記憶體讀取，屬於記憶體密集型操作；從定性分析來看 Bloom Filter 的效能更加



### 實際應用

- Java BitSet
- Redis BitMap
- Google Guava 工具包的 BloomFilter